# Machine Learning Model Comparison

This project presents a comparative analysis of several widely used machine learning models for classification tasks. The goal is to evaluate the performance of each model using a breast cancer dataset and determine which one yields the highest accuracy and predictive reliability.

## ğŸ“Š Models Compared

The following models were implemented and evaluated:

- **K-Nearest Neighbors (KNN)**
- **Kernel Support Vector Machine (Kernel SVM)**
- **Logistic Regression**
- **Naive Bayes**
- **Support Vector Machine (SVM)**
- **Decision Tree**
- **Random Forest**

Each model was assessed using confusion matrix and accuracy score metrics to evaluate its performance.

## ğŸ“ˆ Results

| Model                     | Accuracy Score |
|--------------------------|----------------|
| Decision Tree            | **95.90%**      |
| Kernel SVM               | 95.32%         |
| K-Nearest Neighbors      | 94.73%         |
| Logistic Regression      | 94.73%         |
| Naive Bayes              | 94.15%         |
| Support Vector Machine   | 94.15%         |
| Random Forest            | **93.56%**      |

- ğŸ¥‡ **Best Model**: Decision Tree
- ğŸ¥ˆ **Runner-Up**: Kernel SVM

## ğŸ§ª Dataset

The dataset used for this project is a publicly available **Breast Cancer Dataset**, commonly used for classification problems.

## ğŸ“ Project Structure

- `Data.csv` â€“ Dataset file  
- `*.ipynb` â€“ Jupyter notebooks for each individual model  
- `Presentation - Machine Learning Model Comparison.pdf` â€“ Summary presentation of the project  
- `README.md` â€“ This file  
- `LICENSE` â€“ MIT License

## ğŸ’» How to Run

1. Clone this repository  
   ```bash
   git clone https://github.com/nadhif-royal/ModelComparisonML.git
   ```
2. Open the Jupyter notebooks in your preferred IDE or environment.
3. Run each notebook to view model training, evaluation, and comparison.

## ğŸ“Œ Conclusion

The **Decision Tree** model showed the highest accuracy, making it the best performer in this project. Meanwhile, **Random Forest** had the lowest accuracy. The **Kernel SVM** came close to matching the performance of the Decision Tree, making it a solid alternative.

## ğŸ“¬ Connect with Me

- ğŸ”— [LinkedIn - Royal Nadhif](https://www.linkedin.com/in/royalnadhif50/)  
- ğŸ“¸ [Instagram - @royal_nadhif](https://www.instagram.com/royal_nadhif/)

---
